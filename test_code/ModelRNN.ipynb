{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "RND_STATE = 42\n",
    "np.random.seed(RND_STATE)\n",
    "\n",
    "PATH = ''\n",
    "foldersTrain = {'flow': 'OptFlowTrain/',\n",
    "           'frames': 'FramesTrain/'}\n",
    "\n",
    "foldersValid = {'flow': 'OptFlowValid/',\n",
    "           'frames': 'FramesValid/'}\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "From: https://stackoverflow.com/questions/4623446/how-do-you-sort-files-numerically\n",
    "'''\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesTrain = [PATH + foldersTrain['frames'] + img for img in sorted(os.listdir(foldersTrain['frames']), key=alphanum_key)]\n",
    "flowTrain =  [PATH + foldersTrain['flow'] + img for img in sorted(os.listdir(foldersTrain['flow']), key=alphanum_key)]\n",
    "framesValid = [PATH + foldersValid['frames'] + img for img in sorted(os.listdir(foldersValid['frames']), key=alphanum_key)]\n",
    "flowValid =  [PATH + foldersValid['flow'] + img for img in sorted(os.listdir(foldersValid['flow']), key=alphanum_key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsTrain = pd.read_csv(PATH + 'training_labels.csv')\n",
    "labelsValid = pd.read_csv(PATH + 'valid_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp\n",
    "framesTrain = framesTrain[:labelsTrain.shape[0]]\n",
    "flowTrain = flowTrain[:labelsTrain.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    def __init__(self, img, flow, labels):\n",
    "        self.img = img\n",
    "        self.flow = flow\n",
    "        self.size = len(self.img)\n",
    "        self.y = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        Ximg = []\n",
    "        Ximg.append(cv2.imread(self.img[idx]))\n",
    "        Ximg = np.array(Ximg)\n",
    "        \n",
    "        Xflow = []\n",
    "        Xflow.append(cv2.imread(self.flow[idx]))\n",
    "        Xflow = np.array(Xflow)\n",
    "        \n",
    "\n",
    "        # normalize\n",
    "        for i in range(Ximg[0].shape[-1]):\n",
    "            if np.std(Ximg[0][:, :, i]) > 0:\n",
    "                Ximg[0][:, :, i] = (Ximg[0][:, :, i] - np.mean(Ximg[0][:, :, i])) / np.std(Ximg[0][:, :, i])\n",
    "                \n",
    "        # normalize\n",
    "        for i in range(Xflow[0].shape[-1]):\n",
    "            if np.std(Xflow[0][:, :, i]) > 0:\n",
    "                Xflow[0][:, :, i] = (Xflow[0][:, :, i] - np.mean(Xflow[0][:, :, i])) / np.std(Xflow[0][:, :, i])\n",
    "        \n",
    "        return Ximg[0], Xflow[0], self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataLoader(framesTrain, flowTrain, pd.get_dummies(labelsTrain.iloc[:, 1]).values)\n",
    "valid_dataset = DataLoader(framesValid, flowValid, pd.get_dummies(labelsValid.iloc[:, 1]).values)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                          batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes = 3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.cnn_branch1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.Conv2d(64, 32, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(32, 16, 2),\n",
    "            nn.Conv2d(16, 4, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2,2))\n",
    "        )\n",
    "        \n",
    "        self.cnn_branch2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3),\n",
    "            nn.Conv2d(64, 32, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(32, 16, 2),\n",
    "            nn.Conv2d(16, 4, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2,2))\n",
    "        )\n",
    "\n",
    "        self.linear_branch = nn.Sequential(\n",
    "            nn.Linear(30*30*4*2, 256),  # dimensionality error\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, n_classes),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "        # init layers with weights\n",
    "        for m in self.cnn_branch1.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "        # init layers with weights\n",
    "        for m in self.cnn_branch2.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        for m in self.linear_branch.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1.0)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1, x2  = x1.permute(0,3,1,2), x2.permute(0,3,1,2)\n",
    "        x1,x2 = self.cnn_branch1(x1), self.cnn_branch2(x2)\n",
    "        \n",
    "        # flatten\n",
    "        x1, x2 = x1.reshape(batch_size, -1),x2.reshape(batch_size, -1)\n",
    "        \n",
    "        # concatenate along 1 axis\n",
    "        x = torch.cat((x1, x2), dim = 1)\n",
    "        out = self.linear_branch(x)\n",
    "        return out\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training started...\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0403, Jaccard Accuracy: (23.7500%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-05.\n",
      "\n",
      "Average loss: 0.0403, Jaccard Accuracy: (23.7500%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0403, Jaccard Accuracy: (23.7500%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0399, Jaccard Accuracy: (25.0000%)\n",
      "\n",
      "Epoch    26: reducing learning rate of group 0 to 2.5000e-05.\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n",
      "\n",
      "Average loss: 0.0401, Jaccard Accuracy: (24.3750%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-dd30ef4fb448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total training time {:2f} seconds'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-dd30ef4fb448>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-53f794fb7951>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mstd\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m     return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m-> 3038\u001b[1;33m                          **kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_std\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m--> 140\u001b[1;33m                keepdims=keepdims)\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m# not a scalar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_sch = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=8, verbose=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(torch.device(\"cuda\"))\n",
    "    criterion = criterion.to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    dtype = torch.FloatTensor\n",
    "    for batch_idx, (x1, x2, target) in enumerate(train_loader):\n",
    "        x1, x2, target = Variable(x1).type(dtype), Variable(x2).type(dtype), Variable(target).type(dtype)\n",
    "        if torch.cuda.is_available():\n",
    "            x1, x2 = x1.to(torch.device(\"cuda\")), x2.to(torch.device(\"cuda\"))\n",
    "            target = target.to(torch.device(\"cuda\"))\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x1, x2)\n",
    "\n",
    "        target = torch.argmax(target, dim=1)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_sch.step(loss)\n",
    "\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    preds = np.array([])\n",
    "    targets = np.array([])\n",
    "    \n",
    "    dtype = torch.FloatTensor\n",
    "    for batch_idx, (x1, x2, target) in enumerate(data_loader):\n",
    "        x1, x2, target = Variable(x1).type(dtype), Variable(x2).type(dtype), Variable(target).type(dtype)\n",
    "        if torch.cuda.is_available():\n",
    "            x1, x2 = x1.to(torch.device(\"cuda\")), x2.to(torch.device(\"cuda\"))\n",
    "            target = target.to(torch.device(\"cuda\"))\n",
    "\n",
    "        output = model(x1, x2)\n",
    "        if len(preds) == 0:\n",
    "            if torch.cuda.is_available():\n",
    "                preds = output.cpu().detach().numpy()\n",
    "                targets = target.cpu().detach().numpy()\n",
    "            else:\n",
    "                preds = output.detach().numpy()\n",
    "                targets = target.detach().numpy()\n",
    "        else:\n",
    "            if torch.cuda.is_available():\n",
    "                preds = np.vstack([preds, output.cpu().detach().numpy()])\n",
    "                targets = np.vstack([targets, target.cpu().detach().numpy()])\n",
    "            else:\n",
    "                preds = np.vstack([preds, output.detach().numpy()])\n",
    "                targets = np.vstack([targets, target.detach().numpy()])\n",
    "        \n",
    "        target = torch.argmax(target, dim=1)\n",
    "        loss += F.cross_entropy(output, target).item()\n",
    "\n",
    "\n",
    "    s = np.sum(targets, axis=1) > 0\n",
    "    tot = np.sum(((preds > 0.5) + targets) > 0, axis=1)\n",
    "    intersect = np.sum((preds > 0.5) * targets, axis=1)\n",
    "    acc = intersect[s] / tot[s]\n",
    "    out_acc = np.sum(acc == 1) / len(acc)\n",
    "\n",
    "    loss /= len(data_loader.dataset)\n",
    "\n",
    "    print('\\nAverage loss: {:.4f}, Jaccard Accuracy: ({:.4f}%)\\n'.format(\n",
    "        loss, 100 * out_acc))\n",
    "    return preds, target\n",
    "\n",
    "\n",
    "print('[INFO] Training started...')\n",
    "import time\n",
    "t1 = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    preds, targets = evaluate(train_loader)\n",
    "print('Total training time {:2f} seconds'.format(time.time() - t1))\n",
    "\n",
    "print('[INFO] Training finished')\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "print('[INFO] Model Saved!')\n",
    "\n",
    "print('Predicted labels')\n",
    "print(preds[:10])\n",
    "print('\\n')\n",
    "\n",
    "print('Real labels')\n",
    "print(targets[:10])\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
